我是第一次接触关于网络爬虫方面的知识，之前都是做的web开发。
经过浏览一下网络上的帖子：
我初步的设想是：广度优先：先遍历页面所有的a标签，经过正则匹配获取所有的正确的url，然后进行操作。
                            因为我以前接触过LinkedBlockingDeque，知道它是线程安全，所以采用它作为队列。
                            因为单线程执行很慢，所以考虑使用多线程，因为需要一个存放下载地址的队列，其次
                            因为网络下载很慢，在考虑下载速率的情况下最好下载是单线程，对于下载的内容采用一个队列。
                            其次，对于存放书籍信息也建立一个队列。
                            
但是在开发过程中：当做到解析页面下载内容时，发现使用广度优先对数据的匹配和解析要求很高，
                                因此在对结果无影响的情况下，我换成了深度优先。通过页面下一页的超链接，
                                不停的循环获取页面下一页的超链接地址，之后取到最后一页
      
项目中包说明：
com.splider.douban.bean-------------书籍对象和集合比较的对象
com.splider.douban.contants---------常数类，存放一些必要的常数
com.splider.douban.queue------------分别存放书籍队列，网上下载的内容队列和访问地址队列
com.splider.douban.thread-----------分别存放下载线程和主线程
com.splider.douban.utils------------工具类，主要实现了http下载功能
com.splider.douban.Test-------------测试类，用于对数据进行测试（没有使用Junit）


测试结果：单位-毫秒
起始时间：1483629559550
结束时间：1483629595739
时间差：36189
